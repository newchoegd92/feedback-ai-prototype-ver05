# app.py
# ================== í•™ìŠµ í”¼ë“œë°± AI (Streamlit + Vertex AI íŠœë‹ ëª¨ë¸) ==================
# í•„ìˆ˜: Settings â†’ Secrets ì— ì•„ë˜ í‚¤ë“¤ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
#   project_id, location(=us-central1), tuned_model_name(í’€ ê²½ë¡œ ê¶Œì¥)
#   [gcp_service_account]  â† ì„œë¹„ìŠ¤ê³„ì • JSON ì›ë¬¸
# --------------------------------------------------------------------

import streamlit as st
import pandas as pd
from datetime import datetime

import vertexai
from vertexai.generative_models import (
    GenerativeModel,
    Content,
    Part,
    GenerationConfig,
)
from google.oauth2 import service_account
import google.cloud.aiplatform as aiplatform

# ---------------- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (Streamlitì˜ ì²« í˜¸ì¶œì´ì–´ì•¼ í•¨) ----------------
st.set_page_config(page_title="í•™ìŠµ í”¼ë“œë°± AI", page_icon="ğŸ¸", layout="centered")

# ---------------- Secrets ë¡œë“œ & ê¸°ë³¸ê°’ ----------------
PROJECT_ID = st.secrets.get("project_id", "feedback-ai-prototype-ver05")
LOCATION = st.secrets.get("location", "us-central1")
PROJECT_NUMBER = st.secrets.get("project_number", None)  # ì„ íƒ

_raw_model_name = (st.secrets.get("tuned_model_name") or "").strip()
if not _raw_model_name:
    st.error("Secretsì— 'tuned_model_name'ì´ ì—†ìŠµë‹ˆë‹¤. Settings â†’ Secretsì— tunedModels/... ê°’ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ì§§ì€ í˜•íƒœ(tunedModels/123...)ê°€ ì˜¤ë©´ í’€ ê²½ë¡œë¡œ ì •ê·œí™”
if _raw_model_name.startswith("tunedModels/"):
    base_project = PROJECT_ID or PROJECT_NUMBER
    TUNED_MODEL_NAME = f"projects/{base_project}/locations/{LOCATION}/{_raw_model_name}"
else:
    TUNED_MODEL_NAME = _raw_model_name

if "/tunedModels/" not in TUNED_MODEL_NAME:
    st.error(f"tuned_model_name í˜•ì‹ ì˜¤ë¥˜: {TUNED_MODEL_NAME}\në°˜ë“œì‹œ 'tunedModels/...' ë˜ëŠ” 'projects/.../tunedModels/...' ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

# ---------------- ëª¨ë¸ ë° ì¸ì¦ ì„¤ì • ----------------
def load_model():
    # 1) ì¸ì¦
    try:
        credentials = service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"]
        )
    except Exception as e:
        st.error("Secretsì˜ [gcp_service_account] ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.\n" + repr(e))
        st.stop()

    # 2) Vertex ì´ˆê¸°í™”
    try:
        vertexai.init(project=PROJECT_ID, location=LOCATION, credentials=credentials)
    except Exception as e:
        st.error("Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨: project/location/ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.\n" + repr(e))
        st.stop()

    # 3) íŠœë‹ ëª¨ë¸ ë¡œë“œ
    try:
        tuned = GenerativeModel(TUNED_MODEL_NAME)
        return tuned, None
    except Exception as e:
        # í´ë°±: ë² ì´ìŠ¤ ëª¨ë¸ë¡œë¼ë„ ë™ì‘ í™•ì¸ ê°€ëŠ¥í•˜ê²Œ
        fallback = GenerativeModel("gemini-1.5-flash-001")
        return fallback, e

model, tuned_model_error = load_model()

# ---------------- ì„¸ì…˜ ìƒíƒœ ----------------
if "log" not in st.session_state:
    st.session_state.log = []
if "last_ai" not in st.session_state:
    st.session_state.last_ai = ""
if "last_prompt" not in st.session_state:
    st.session_state.last_prompt = ""

# ---------------- ì‚¬ì´ë“œë°”: í™˜ê²½/ë””ë²„ê·¸ ----------------
with st.sidebar:
    st.caption("í™˜ê²½ ì •ë³´")
    st.write(f"Project: `{PROJECT_ID}`")
    st.write(f"Location: `{LOCATION}`")
    st.write(f"aiplatform: `{aiplatform.__version__}`")
    st.write(f"tuned_model_name: `{TUNED_MODEL_NAME}`")
    if tuned_model_error:
        st.warning("íŠœë‹ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ â†’ ì„ì‹œë¡œ ë² ì´ìŠ¤ ëª¨ë¸ ì‚¬ìš© ì¤‘")
        st.exception(tuned_model_error)

# ---------------- UI ----------------
st.title("ğŸ¸ ë…Tì˜ í•™ìŠµ í”¼ë“œë°± AI")
st.markdown("---")

user_prompt = st.text_area("í•™ìƒì˜ ìƒí™©ì„ ìì„¸íˆ ì…ë ¥í•´ì£¼ì„¸ìš”:", height=180, key="prompt_input")

col1, col2 = st.columns([1, 1])
with col1:
    gen_clicked = st.button("í”¼ë“œë°± ìƒì„±í•˜ê¸°", use_container_width=True)
with col2:
    clear_clicked = st.button("í™”ë©´ ì´ˆê¸°í™”", use_container_width=True)

if clear_clicked:
    st.session_state.last_ai = ""
    st.session_state.last_prompt = ""
    st.rerun()

# ---------------- í˜¸ì¶œ í•¨ìˆ˜ ----------------
def generate_ai_response(prompt_text: str) -> str:
    """
    1ì°¨: ìµœì†Œ í¬ë§· í˜¸ì¶œ (ê°€ì¥ í˜¸í™˜ì„±ì´ ë†’ìŒ)
    2ì°¨: GenerationConfig ê°ì²´ë§Œ ì‚¬ìš©í•´ ì˜µì…˜ ì ìš©
    """
    # 1) ìµœì†Œ í¬ë§·
    try:
        resp = model.generate_content([Content(role="user", parts=[Part.from_text(prompt_text)])])
        return resp.text or ""
    except Exception:
        pass

    # 2) ì •ì‹ ê°ì²´ ê¸°ë°˜ ì„¤ì • (dict ê¸ˆì§€)
    cfg = GenerationConfig(max_output_tokens=512, temperature=0.7)
    resp = model.generate_content(
        [Content(role="user", parts=[Part.from_text(prompt_text)])],
        generation_config=cfg,
    )
    return resp.text or ""

# ---------------- ìƒì„± ë²„íŠ¼ ì²˜ë¦¬ ----------------
if gen_clicked:
    if not user_prompt.strip():
        st.warning("í•™ìƒì˜ ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("AIê°€ ê°•ì‚¬ë‹˜ì˜ ì² í•™ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                ai_text = generate_ai_response(user_prompt)
                st.session_state.last_ai = ai_text
                st.session_state.last_prompt = user_prompt
            except Exception as e:
                st.error("ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.exception(e)

# ---------------- ê²°ê³¼/í¸ì§‘/ì €ì¥ ----------------
if st.session_state.last_ai:
    st.subheader("ğŸ¤– AI ì´ˆì•ˆ")
    st.write(st.session_state.last_ai)

    st.markdown("### âœï¸ ìµœì¢… ìŠ¹ì¸ìš©: ìˆ˜ì •/ë³´ì™„í•´ì„œ ì €ì¥")
    approved = st.text_area(
        "í•„ìš”í•˜ë©´ ì•„ë˜ì—ì„œ ì§ì ‘ ê³ ì³ì„œ 'ê¸°ë¡ ì €ì¥'ì„ ëˆ„ë¥´ì„¸ìš”.",
        value=st.session_state.last_ai,
        height=240,
        key="approved_area",
    )

    save = st.button("ê¸°ë¡ ì €ì¥", type="primary")
    if save:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.log.append(
            {
                "timestamp": timestamp,
                "prompt": st.session_state.last_prompt,
                "ai_response": st.session_state.last_ai,
                "approved_response": approved.strip(),
            }
        )
        st.success("ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ CSVë¡œ ë‚´ë ¤ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ---------------- ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ----------------
if st.session_state.log:
    st.markdown("---")
    st.subheader("ğŸ“ í”¼ë“œë°± ê¸°ë¡ ë‹¤ìš´ë¡œë“œ")
    st.caption("AI ì´ˆì•ˆê³¼ ê°•ì‚¬ë‹˜ì´ ìŠ¹ì¸/ìˆ˜ì •í•œ ìµœì¢… ë‹µë³€ì´ í•¨ê»˜ ì €ì¥ë©ë‹ˆë‹¤.")
    df = pd.DataFrame(st.session_state.log)
    csv = df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
    st.download_button(
        label="CSV íŒŒì¼ë¡œ ëª¨ë“  ê¸°ë¡ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name="feedback_log.csv",
        mime="text/csv",
    )

    if st.button("ì„¸ì…˜ ë¡œê·¸ ë¹„ìš°ê¸°"):
        st.session_state.log = []
        st.success("ì„¸ì…˜ ë¡œê·¸ë¥¼ ë¹„ì› ìŠµë‹ˆë‹¤.")
