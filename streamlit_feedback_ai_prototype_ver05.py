# app.py â€” í•™ìŠµ í”¼ë“œë°± AI (Google GenAI + Vertex íŠœë‹ ëª¨ë¸)

import streamlit as st
import pandas as pd
from datetime import datetime

from google import genai
from google.genai import types
from google.oauth2 import service_account

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="í•™ìŠµ í”¼ë“œë°± AI", page_icon="ğŸ¸", layout="centered")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Secrets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ID    = st.secrets.get("project_id", "feedback-ai-prototype-ver05")
LOCATION      = st.secrets.get("location", "us-central1")
PROJECT_NUMBER = st.secrets.get("project_number", None)  # ì„ íƒ

RAW_TUNED = (st.secrets.get("tuned_model_name") or "").strip()
if not RAW_TUNED:
    st.error("Secretsì— tuned_model_nameì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ì§§ì€ ê²½ë¡œë©´ í’€ ê²½ë¡œë¡œ, ê·¸ë¦¬ê³  ê°€ëŠ¥í•˜ë©´ í”„ë¡œì íŠ¸ 'ë„˜ë²„'ë¥¼ ìš°ì„  ì‚¬ìš©
if RAW_TUNED.startswith("tunedModels/"):
    base_project = PROJECT_NUMBER or PROJECT_ID
    TUNED_MODEL_NAME = f"projects/{base_project}/locations/{LOCATION}/{RAW_TUNED}"
else:
    TUNED_MODEL_NAME = RAW_TUNED

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¸ì¦ & í´ë¼ì´ì–¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â˜… OAuth scope í•„ìˆ˜ (invalid_scope ë°©ì§€)
SCOPES = ["https://www.googleapis.com/auth/cloud-platform"]

try:
    credentials = service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"],
        scopes=SCOPES,  # â† ì¤‘ìš”
    )
except Exception as e:
    st.error("Secretsì˜ [gcp_service_account]ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.\n" + repr(e))
    st.stop()

client = genai.Client(
    vertexai=True,
    project=PROJECT_ID,
    location=LOCATION,
    credentials=credentials,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¸ì…˜ ìƒíƒœ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "log" not in st.session_state:
    st.session_state.log = []
if "last_ai" not in st.session_state:
    st.session_state.last_ai = ""
if "last_prompt" not in st.session_state:
    st.session_state.last_prompt = ""
if "used_model" not in st.session_state:
    st.session_state.used_model = TUNED_MODEL_NAME
if "tuned_error" not in st.session_state:
    st.session_state.tuned_error = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("**í™˜ê²½ ì •ë³´**")
    st.write(f"Project: `{PROJECT_ID}`")
    st.write(f"Location: `{LOCATION}`")
    st.write(f"tuned_model_name: `{TUNED_MODEL_NAME}`")
    st.write(f"scopes: `{', '.join(SCOPES)}`")
    if st.session_state.tuned_error:
        st.warning("íŠœë‹ ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨ â†’ ë² ì´ìŠ¤ ëª¨ë¸ í´ë°± ì‚¬ìš© ì¤‘")
        st.exception(st.session_state.tuned_error)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ¸ ë…Tì˜ í•™ìŠµ í”¼ë“œë°± AI")
st.markdown("---")
user_prompt = st.text_area("í•™ìƒì˜ ìƒí™©ì„ ìì„¸íˆ ì…ë ¥í•´ì£¼ì„¸ìš”:", height=180, key="prompt_input")

col1, col2 = st.columns([1, 1])
with col1:
    gen_clicked = st.button("í”¼ë“œë°± ìƒì„±í•˜ê¸°", use_container_width=True)
with col2:
    clear_clicked = st.button("í™”ë©´ ì´ˆê¸°í™”", use_container_width=True)

if clear_clicked:
    st.session_state.last_ai = ""
    st.session_state.last_prompt = ""
    st.session_state.used_model = TUNED_MODEL_NAME
    st.session_state.tuned_error = None
    st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í˜¸ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_model(model_name: str, prompt_text: str) -> str:
    resp = client.models.generate_content(
        model=model_name,
        contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt_text)])],
        config=types.GenerateContentConfig(
            temperature=0.7,
            max_output_tokens=1024,
        ),
    )
    return resp.text or ""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒì„± ë²„íŠ¼ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if gen_clicked:
    if not user_prompt.strip():
        st.warning("í•™ìƒì˜ ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("AIê°€ ê°•ì‚¬ë‹˜ì˜ ì² í•™ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                ai_text = call_model(TUNED_MODEL_NAME, user_prompt)
                st.session_state.used_model = TUNED_MODEL_NAME
                st.session_state.tuned_error = None
            except Exception as tuned_err:
                st.session_state.tuned_error = tuned_err
                try:
                    base_project = PROJECT_NUMBER or PROJECT_ID
                    base_model = f"projects/{base_project}/locations/{LOCATION}/publishers/google/models/gemini-2.5-pro"
                    ai_text = call_model(base_model, user_prompt)
                    st.session_state.used_model = base_model
                except Exception as base_err:
                    st.error("ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    st.exception(tuned_err)
                    st.exception(base_err)
                raise
            st.session_state.last_ai = ai_text
            st.session_state.last_prompt = user_prompt

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²°ê³¼/í¸ì§‘/ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.last_ai:
    st.subheader("ğŸ¤– AI ì´ˆì•ˆ")
    st.caption(f"ì‚¬ìš©í•œ ëª¨ë¸: `{st.session_state.used_model}`")
    st.write(st.session_state.last_ai)

    st.markdown("### âœï¸ ìµœì¢… ìŠ¹ì¸ìš©: ìˆ˜ì •/ë³´ì™„í•´ì„œ ì €ì¥")
    approved = st.text_area(
        "í•„ìš”í•˜ë©´ ì•„ë˜ì—ì„œ ì§ì ‘ ê³ ì³ì„œ 'ê¸°ë¡ ì €ì¥'ì„ ëˆ„ë¥´ì„¸ìš”.",
        value=st.session_state.last_ai,
        height=240,
        key="approved_area",
    )

    if st.button("ê¸°ë¡ ì €ì¥", type="primary"):
        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.log.append(
            {
                "timestamp": ts,
                "prompt": st.session_state.last_prompt,
                "ai_response": st.session_state.last_ai,
                "approved_response": approved.strip(),
                "used_model": st.session_state.used_model,
            }
        )
        st.success("ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ CSVë¡œ ë‚´ë ¤ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.log:
    st.markdown("---")
    st.subheader("ğŸ“ í”¼ë“œë°± ê¸°ë¡ ë‹¤ìš´ë¡œë“œ")
    st.caption("AI ì´ˆì•ˆê³¼ ê°•ì‚¬ë‹˜ì´ ìŠ¹ì¸/ìˆ˜ì •í•œ ìµœì¢… ë‹µë³€ì´ í•¨ê»˜ ì €ì¥ë©ë‹ˆë‹¤.")
    df = pd.DataFrame(st.session_state.log)
    csv = df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
    st.download_button(
        label="CSV íŒŒì¼ë¡œ ëª¨ë“  ê¸°ë¡ ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name="feedback_log.csv",
        mime="text/csv",
    )
    if st.button("ì„¸ì…˜ ë¡œê·¸ ë¹„ìš°ê¸°"):
        st.session_state.log = []
        st.success("ì„¸ì…˜ ë¡œê·¸ë¥¼ ë¹„ì› ìŠµë‹ˆë‹¤.")
